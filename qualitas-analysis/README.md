### How to replicate the experiments.

## Set up the corpus.

First get a copy of the programs from the Qualitas suite.
Create a directory to put them in - let's call it QDIR.
Create QDIR/qualitas, and run the script get-qualitas.sh in there.
This clones the repos and does some renaming to tidy things up.
You should end up with 51 directories and about 4.8G of files.

Edit qualitas.py, and change the variable _CORPUS_ROOT to be your
QDIR.  If you now run qualitas.py it should print out your directory:

       python3 qualitas.py

This is how the remaining shell scripts figure out where things are.

## Get the 'old' versions of each.

For our longitudinal study we get version of the corpus at 31 Dec from
2005 to 2016. Run the file rollback.py and save the output somewhere,
e.g.:

			python3 rollback.py > roller.sh
This takes a while as it has to go through the repos and find the
relevant versions for each year and each app.

Now create a folder for these older versions as: QDIR/older-versions
Go here and run roller.sh.  This will copy each app from your original
version and roll it back to the relevant version for each year.
Have a look at roller.sh: it basically has the SHAs for the versions
you want; the rest is just copying and a git reset.


## (1) Data for table 1: basic counts, commits

The basic information is derived from running list-details.sh.
This just uses 'find' and 'wc' to get file and line counts, and uses
'git' to get the first commit.

Getting the last commit was a little more troublesome, since the apps
do not always tag things consistently.  To deal with this, I run
list-recent-tags.sh to get the most recent 20 tags, and then manually
pick out the most suitable-looking one.  In most cases this is the
first one, but some apps are a bit more awkward.


## (2) Data for table 2: pass rates.

Assuming you want to build and run the front-end (and have flex, bison
and gcc installed) you want to run qualitas-test.py.  For example:

  python3 qualitas_test.py 2.7 astropy

will run the v2.7 front-end over astropy.  You'll set it building the
2.7 front-end the first time around;l after this it just uses it.
The output is a latex table with the pass rate.

You can try multiple versions and apps, e.g.

    python3 qualitas_test.py 2.7 astropy 3.1 gramps

will run both 2.7 and 3.1 front-ends on these two apps.

The pass rates for the older versions are generated by historical_comply.py
If you want to bypass this, the pass rates for each Python front-end
and each version of the Qualitas suite are given in the files in

    data/pass_rates/

For example, 'qualitas-2010-12-31-3.2.dat' has the pass rates using
the 2010 version of the apps and the Python 3.2 front-end.


## Data for Fig 3: activity for (dates of) Python 3 versions

The script count-commit-dates.sh gets the commit information from the
git logs for the latest version of each app.  It then runs a loop to
categorise these into the various date ranges corresponding to the
Python releases, which it gets by running python_versions.py.

This data is written to data/commit-data.csv, which shows the
number of commits for each Python 3.x version from 3.6 down to 3.0,
and then the total no. of commits at the end).

For example, in the paper we give the percentages for astropy; the
actual numbers behind this is:
>grep astropy data/commit-data.csv 
     astropy     11   4264  11459  17912  19759  19759  19759 19759

The violin plot is created by the script plot_commits.py which reads
this file.


## Data for Fig 4 and 5: numbers of committers and creators

The data is collected by the script count-authors.sh. 
This is just a matter of grepping the git logs for the relevant
information.

The data is then stored in the file data/authors.txt.  For each app
this lists the number of committers and creators.  We also counted the
number of committers with more than 5, 10 etc. commits, but didn't use
this in the paper.

The two box-plots are then generated by the script plot_authors.py.

## Data for Figures 6 and 7: changes in compliance level.

This is produced by historical_comply.py.
It will read the pass rate data from the files if they're there,
otherwise it will regenerate the pass rates.  The series (2 or 3) is
hard coded at the end of the file.

## Data for section 6: back-ported features.

This is produced by a specialised version of the 2.7 front-end,
augmented by some counters.  This front-end is in the featFind
directory.
